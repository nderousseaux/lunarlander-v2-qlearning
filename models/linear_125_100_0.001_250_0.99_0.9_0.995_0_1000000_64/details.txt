activation_function: linear
hidden_layers: [125, 100]
learning_rate: 0.001
epoch: 250
gamma: 0.99
init_epsilon: 0.9
epsilon_dec: 0.995
epsilon_end: 0
mem_size: 1000000
batch_size: 64
