activation_function: linear
hidden_layers: [150, 120]
learning_rate: 0.001
epoch: 500
gamma: 0.99
init_epsilon: 1.0
epsilon_dec: 0.996
epsilon_end: 0.01
mem_size: 1000000
batch_size: 64
